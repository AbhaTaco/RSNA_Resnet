{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f4cc6f9c-19ea-46b6-8943-8e06573a78ac",
    "_uuid": "dd46f56d-f922-421a-8ed5-1a2bb728cb25",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import FloatTensor, LongTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score,  roc_auc_score, confusion_matrix\n",
    "\n",
    "# For RSNA dataset\n",
    "from albumentations import (ToFloat, Normalize, VerticalFlip, HorizontalFlip, Compose, Resize,\n",
    "                            RandomBrightnessContrast, HueSaturationValue, Blur, GaussNoise,\n",
    "                            Rotate, RandomResizedCrop, Cutout, ShiftScaleRotate, ToGray)\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pydicom # for DICOM images\n",
    "\n",
    "import gc \n",
    "\n",
    "# For config file\n",
    "import argparse\n",
    "import yaml\n",
    "import sys\n",
    "\n",
    "# ---------- #\n",
    "\n",
    "# Setting Training Configuration\n",
    "\n",
    "sys.argv = ['-f']\n",
    "\n",
    "def set_params(config_path):\n",
    "    with open(config_path) as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--folds', dest='FOLDS', default=config.get('FOLDS'))\n",
    "    parser.add_argument('--epochs', dest='EPOCHS', default=config.get('EPOCHS'))\n",
    "    parser.add_argument('--patience', dest='PATIENCE', default=config.get('PATIENCE'))\n",
    "    parser.add_argument('--workers', dest='WORKERS', default=config.get('WORKERS'))\n",
    "    parser.add_argument('--lr', dest='LR', default=config.get('LR'))\n",
    "    parser.add_argument('--wd', dest='WD', default=config.get('WD'))\n",
    "    parser.add_argument('--lr_patience', dest='LR_PATIENCE', default=config.get('LR_PATIENCE'))\n",
    "    parser.add_argument('--lr_factor', dest='LR_FACTOR', default=config.get('LR_FACTOR'))\n",
    "    parser.add_argument('--batch_size1', dest='BATCH_SIZE1', default=config.get('BATCH_SIZE1'))\n",
    "    parser.add_argument('--batch_size2', dest='BATCH_SIZE2', default=config.get('BATCH_SIZE2'))\n",
    "    parser.add_argument('--version', dest='VERSION', default=config.get('VERSION'))\n",
    "    parser.add_argument('--model', dest='MODEL', default=config.get('MODEL'))\n",
    "\n",
    "    args = parser.parse_args()    \n",
    "    return args\n",
    "\n",
    "# ---------- #\n",
    "\n",
    "# Dataclass for loading into model\n",
    "csv_columns = ['laterality', 'age', 'implant', 'site_id', 'machine_id']\n",
    "\n",
    "class RSNADataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, \n",
    "                 is_train=True):\n",
    "        self.dataframe, self.is_train = dataframe, is_train\n",
    "        \n",
    "        \n",
    "        # Data Augmentation (custom for each dataset type)\n",
    "        if is_train:\n",
    "            self.transform = Compose([RandomResizedCrop(height=224, width=224),\n",
    "                                       ShiftScaleRotate(rotate_limit=90, scale_limit = [0.8, 1.2]),\n",
    "                                       HorizontalFlip(p = 0.5),\n",
    "                                       VerticalFlip(p = 0.5),\n",
    "                                       ToTensorV2()])\n",
    "        else:\n",
    "            self.transform = Compose([ToTensorV2()])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        '''Take each row in batch at a time.'''\n",
    "        \n",
    "        # Select path and read image\n",
    "        image_path = self.dataframe['path_CC'][index]\n",
    "        image = pydicom.dcmread(image_path).pixel_array.astype(np.float32)\n",
    "        \n",
    "        # For this image also import .csv information\n",
    "        csv_data = np.array(self.dataframe.iloc[index][csv_columns].values, dtype=np.float32)\n",
    "\n",
    "        # Apply transforms\n",
    "        image_ar = pydicom.dcmread(self.dataframe['path_CC'].iloc[1]).pixel_array.astype(np.float32)\n",
    "        transf_image = self.transform(image=image_ar)['image']\n",
    "\n",
    "        # Change image from 1 channel (B&W) to 3 channels\n",
    "        transf_image = np.concatenate([transf_image, transf_image, transf_image], axis=0)\n",
    "        \n",
    "        # Return info\n",
    "        if self.is_train:\n",
    "            return  transf_image, csv_data, self.dataframe['cancer'][index]\n",
    "        \n",
    "        else:\n",
    "            return {\"image\": transf_image, \n",
    "                    \"csv\": csv_data,\n",
    "                    \"target\": self.dataframe['cancer'][index]}\n",
    "\n",
    "\n",
    "# ---------- #\n",
    "        \n",
    "# Function for training model\n",
    "\n",
    "def train_folds(args, model, train_original):\n",
    "    \n",
    "    # Training params from configuration in args\n",
    "    \n",
    "    FOLDS = args.FOLDS\n",
    "    EPOCHS = args.EPOCHS\n",
    "    PATIENCE = args.PATIENCE\n",
    "    WORKERS = args.WORKERS\n",
    "    LR = args.LR\n",
    "    WD = args.WD\n",
    "    LR_PATIENCE = args.LR_PATIENCE            \n",
    "    LR_FACTOR = args.LR_FACTOR            \n",
    "\n",
    "    BATCH_SIZE1 = args.BATCH_SIZE1           # for train\n",
    "    BATCH_SIZE2 = args.BATCH_SIZE2           # for valid\n",
    "\n",
    "    VERSION = args.VERSION\n",
    "    MODEL = args.MODEL\n",
    "    \n",
    "  \n",
    "    # Split in folds\n",
    "    strat_fold = StratifiedKFold(n_splits = FOLDS)\n",
    "\n",
    "    # Generate indices to split data into training and test set.\n",
    "    k_folds = strat_fold.split(X = np.zeros(len(train_original)), \n",
    "                               y = train_original['cancer'].astype(int))\n",
    "    \n",
    "    # For each fold\n",
    "    for i, (train_index, valid_index) in enumerate(k_folds):\n",
    "        \n",
    "        print(f\"---------- Fold: {i+1} ----------\")\n",
    "      \n",
    "        # --- Create Instances ---\n",
    "        # Best ROC score in this fold\n",
    "        best_roc = None\n",
    "        # Reset patience before every fold\n",
    "        patience_f = PATIENCE\n",
    "\n",
    "        # Optimizer/ Scheduler/ Criterion\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = LR, \n",
    "                                     weight_decay=WD)\n",
    "        scheduler = ReduceLROnPlateau(optimizer=optimizer, mode='max', \n",
    "                                      patience=LR_PATIENCE, verbose=True, factor=LR_FACTOR)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        \n",
    "        # --- Read in Data ---\n",
    "        train_data = train_original.iloc[train_index].reset_index(drop=True)\n",
    "        valid_data = train_original.iloc[valid_index].reset_index(drop=True)\n",
    "\n",
    "        # Create Data instances\n",
    "        train = RSNADataset(train_data, is_train=True)\n",
    "        valid = RSNADataset(valid_data, is_train=True)\n",
    "\n",
    "        # Dataloaders\n",
    "        train_loader = DataLoader(train, batch_size=BATCH_SIZE1, \n",
    "                                  shuffle=True)\n",
    "        valid_loader = DataLoader(valid, batch_size=BATCH_SIZE2, \n",
    "                                  shuffle=False)\n",
    "\n",
    "        \n",
    "        # === EPOCHS ===\n",
    "        for epoch in range(EPOCHS):\n",
    "            start_time = time()\n",
    "            correct = 0\n",
    "            train_losses = 0\n",
    "            \n",
    "            \n",
    "            # === TRAIN ===\n",
    "            # Sets the module in training mode.\n",
    "            model.train()\n",
    "\n",
    "            # For each batch\n",
    "            for k, (image, meta, targets) in enumerate(train_loader):                 \n",
    "                \n",
    "                # Clear gradients first; very important\n",
    "                # usually done BEFORE prediction\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Log Probabilities & Backpropagation\n",
    "                out = model(image, meta)\n",
    "\n",
    "                loss = criterion(out, targets.unsqueeze(1).float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # --- Save information after this batch ---\n",
    "                # Save loss\n",
    "                train_losses += loss.item()\n",
    "                # From log probabilities to actual probabilities\n",
    "                train_preds = torch.round(torch.sigmoid(out)) # 0 and 1\n",
    "                # Number of correct predictions\n",
    "                correct += (train_preds.cpu() == targets.cpu().unsqueeze(1)).sum().item()\n",
    "\n",
    "            # Compute Train Accuracy\n",
    "            train_acc = correct / len(train_index)\n",
    "\n",
    "            # === EVAL ===\n",
    "            # Sets the model in evaluation mode.\n",
    "            model.eval()\n",
    "\n",
    "            # Create matrix to store evaluation predictions (for accuracy)\n",
    "            \n",
    "            valid_preds = torch.zeros(size = (len(valid_index), 1), device = torch.device('cpu'), dtype=torch.float32)\n",
    "\n",
    "            # Disables gradients (we need to be sure no optimization happens)\n",
    "            with torch.no_grad():\n",
    "                for k, (image, meta, targets) in enumerate(valid_loader):\n",
    "                    out = model(image, meta)\n",
    "                    pred = torch.sigmoid(out)\n",
    "                    valid_preds[k*image.shape[0] : k*image.shape[0] + image.shape[0]] = pred\n",
    "\n",
    "\n",
    "                # Calculate accuracy\n",
    "                valid_acc = accuracy_score(valid_data['cancer'].values, \n",
    "                                           np.where(valid_preds > 0.5, 1, 0))\n",
    "               \n",
    "                # Calculate ROC\n",
    "                valid_roc = roc_auc_score(valid_data['cancer'].values, \n",
    "                                          valid_preds)\n",
    "               \n",
    "                # Calculate time on Train + Eval\n",
    "                #duration = str(dtime.timedelta(seconds=time() - start_time))[:7]\n",
    "\n",
    "\n",
    "                # PRINT INFO\n",
    "                final_logs = '{} | Epoch: {}/{} | Loss: {:.4} | Acc_tr: {:.3} | Acc_vd: {:.3} | ROC: {:.3}'.\\\n",
    "                                format('0', epoch+1, EPOCHS, \n",
    "                                       train_losses, train_acc, valid_acc, valid_roc)\n",
    "                print(final_logs)\n",
    "\n",
    "\n",
    "                # === SAVE MODEL ===\n",
    "\n",
    "                # Update scheduler (for learning_rate)\n",
    "                scheduler.step(valid_roc)\n",
    "                # Name the model\n",
    "                model_name = f\"Fold{i+1}_Epoch{epoch+1}_ValidAcc{valid_acc:.3f}_ROC{valid_roc:.3f}.pth\"\n",
    "\n",
    "                # Update best_roc\n",
    "                if not best_roc: # If best_roc = None\n",
    "                    best_roc = valid_roc\n",
    "                    torch.save(model.state_dict(), model_name)\n",
    "                    continue\n",
    "\n",
    "                if valid_roc > best_roc:\n",
    "                    best_roc = valid_roc\n",
    "                    # Reset patience (because we have improvement)\n",
    "                    patience_f = PATIENCE\n",
    "                    torch.save(model.state_dict(), model_name)\n",
    "                else:\n",
    "                    # Decrease patience (no improvement in ROC)\n",
    "                    patience_f = patience_f - 1\n",
    "                    if patience_f == 0:\n",
    "                        stop_logs = 'Early stopping (no improvement since 3 models) | Best ROC: {}'.\\\n",
    "                                    format(best_roc)\n",
    "                        add_in_file(stop_logs, f)\n",
    "                        print(stop_logs)\n",
    "                        break\n",
    "\n",
    "\n",
    "        # === CLEANING ===\n",
    "        # Clear memory\n",
    "        del train, valid, train_loader, valid_loader, image, targets\n",
    "        gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
